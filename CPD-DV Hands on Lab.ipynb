{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT- IBM Cloud Pak for Data - Data Virtualization- DRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "* What is Data Virtualization\n",
    "* Why are the benefit to my business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to find this sample online\n",
    "You can find a copy of this notebook at https://github.com/Db2-DTE-POC/db2dmc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jupyter notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to IBM Cloud Pak for Data\n",
    "For this lab you will be assigned two IBM Cloud Pak for Data User IDs: A Data Engineer userid and and end-user userid.\n",
    "* **Engineer:**\n",
    "    * ID: LABDATAENGINEER1\n",
    "    * PASSWORD: password\n",
    "* **User:**\n",
    "    * ID: LABUSER1\n",
    "    * PASSWORD: password\n",
    "\n",
    "To get started, sign in using you Engineer id:\n",
    "1. Click the following link to open the IBM Cloud Pak for Data Console: https://services-uscentral.skytap.com:9152/\n",
    "2. Sign in using the Engineer userid and password\n",
    "3. Click the icon at the very top right of the webpage\n",
    "4. Click **Profile and settings**\n",
    "5. Click **Permissions** and review the user permissions for this user\n",
    "6. Click the **three bar menu** at the very top left of the console webpage\n",
    "7. Click **Data Virtualization**\n",
    "8. Click the carrot symbol beside **Menu** below the Data Virtualization title\n",
    "This displays the actions available to your user. Different user have access to more or fewer menu options depending on their role in Data Virtualization. \n",
    "\n",
    "As a Data Engineer you can:\n",
    "* Add and modify Data sources. Each source is a connetion to a single database, either inside or outside of IBM Cloud Pak for Data.\n",
    "* Virtualize data. This makes tables in other data sources look and act like tables that are local to the Data Virtualization database\n",
    "* Work with the data you have virtualized.\n",
    "* Write SQL to access and join data that you have virtualized\n",
    "* See detailed in formation on how to connect external analytic tools and applications to your virtualized data\n",
    "\n",
    "As a User you can only:\n",
    "* Work with data that has been virtualized for you\n",
    "* Write SQL to work with that data\n",
    "* See detailed connection information\n",
    "\n",
    "As an Administrator (only available to the course instructor) you can also:\n",
    "* Manage IBM Cloud Pak for Data User Access and Roles\n",
    "* Create and Manage Data Caches to accelerate performance\n",
    "* Change key service setttings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data Source Connections\n",
    "Let's start by looking at the the Data Source Connections that are already available. \n",
    "\n",
    "    **Insert Graphic**\n",
    "\n",
    "1. Click the Data Virtualization menu and select **Data Sources**.\n",
    "2. Click the **icon below the menu with a circle with three connected dots**.\n",
    "    This displays the Data Source Graph with 8 active data sources:\n",
    "    * 4 Db2 Family Databases hosted on premises, IBM Cloud, Azure and AWS\n",
    "    * 1 EDB Postgres Database on Azure\n",
    "    * 1 zOS VSAM file\n",
    "    * 1 Informix Database running on premises \n",
    "We are not going to add a new data source but just go through the steps so you can review the available datasources:\n",
    "1. Click **+ Add** at the left of the console screen\n",
    "2. Select **Add data source**\n",
    "You can see a history of other data source connection information that was used before. This history is maintain to make reconnecting to data sources easier and faster.\n",
    "3. Click **Add connection**\n",
    "4. Click the field below **Connection type**\n",
    "5. Scroll through all the **available data sources** to see the available connection types\n",
    "6. Select **different data connection types** from the list to see the information required to connect to a new data source. \n",
    "At a minumum you typically need the host URL and port address, database name, userid and password. You can also connect using an SSL certificate that can be dragged and dropped directly into the console interface. \n",
    "7. Click **Cancel**\n",
    "8. Click **Cancel**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Virtualiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part One Exploring the Interface\n",
    "Now that you understand how to connect to data sources you can start virtualizing data. Much of the work has already been done for you. IBM Cloud Pak for Data searches through the available data sources and compiles a single large inventory of all the tables and data available to virtualize in IBM Cloud Pak for Data. \n",
    "1. Click the Data Virtualization menu and select **Data Sources**.\n",
    "2. Select to browse for **Tables**\n",
    "3. Check the total number of available tables at the top of the list. There should be well over 500 available.\n",
    "4. Enter \"STOCK\" into the search field and hit **Enter**. Any tables with the string **STOCK** in the tables name, the table schema or with a colunn title that includes **STOCK** will appear in the search results. \n",
    "5. Hover your mouse pointer to the far right side to the search results table. A **eye** icon will appear on each row as you move your mouse. \n",
    "6. Click the **eye** icon beside one table. This displays a preview of the data in the selected table.\n",
    "7. Click **X** at the top right of the dialog box to return to the search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part Two Creating a New Table\n",
    "So that each user in this lab can have their own data to virtualize you will create your own table in a database.\n",
    "In this part of the lab you will use this Jupyter notebook and Phyton code to connect to a source database, create a simple table and populate it with data. IBM Cloud Pak for Data will automatically detect the change in the source database and make the new table available for virtualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to connect to one of our remote data sources directly as if we were part of the team builing a new business application. Since each lab user will create their own table in their own schema the first thing you need to do is update and run the cell below with your engineer name. \n",
    "1. Click on the cell below.\n",
    "2. Update the name in quotes to match your engineer name\n",
    "3. Click **Run** from the Jupyter notebook menu above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting your userID\n",
    "engineer = 'LABDATAENGINEER1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the lab relies on a Jupyter notebook extension, commonly refer to as a \"magic\" command, to connect to a Db2 database. To use the commands you load load the extension by running another notebook call db2 that contains all the required code \n",
    "<pre>\n",
    "&#37;run db2.ipynb\n",
    "</pre>\n",
    "The cell below loads the Db2 extension. Note that it will take a few seconds for the extension to load, so you should generally wait until the \"Db2 Extensions Loaded\" message is displayed in your notebook. \n",
    "1. Click the cell below\n",
    "2. Click **Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db2 Extensions Loaded.\n"
     ]
    }
   ],
   "source": [
    "%run db2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to Db2\n",
    "\n",
    "Before any SQL commands can be issued, a connection needs to be made to the Db2 database that you will be using. \n",
    "\n",
    "The Db2 magic command tracks whether or not a connection has occured in the past and saves this information between notebooks and sessions. When you start up a notebook and issue a command, the program will reconnect to the database using your credentials from the last session. In the event that you have not connected before, the system will prompt you for all the information it needs to connect. This information includes:\n",
    "\n",
    "- Database name\n",
    "- Hostname\n",
    "- PORT \n",
    "- Userid\n",
    "- Password\n",
    "\n",
    "Run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "%sql CONNECT TO BLUDB USER user999 USING t1cz?K9-X1_Y-2Wi HOST services-uscentral.skytap.com PORT 9094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the connection is working. Run the following cell. It lists the tables in the database in the **DVDEMO** schema. Only the first 5 tables are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABNAME</th>\n",
       "      <th>OWNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ACCOUNTS</td>\n",
       "      <td>USER999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CUSTOMERS</td>\n",
       "      <td>USER999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>STOCK_HISTORY</td>\n",
       "      <td>USER999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>STOCK_SYMBOLS</td>\n",
       "      <td>USER999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>STOCK_TRANSACTIONS</td>\n",
       "      <td>USER999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TABNAME     OWNER\n",
       "0            ACCOUNTS  USER999 \n",
       "1           CUSTOMERS  USER999 \n",
       "2       STOCK_HISTORY  USER999 \n",
       "3       STOCK_SYMBOLS  USER999 \n",
       "4  STOCK_TRANSACTIONS  USER999 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select TABNAME, OWNER from syscat.tables where TABSCHEMA = 'DVDEMO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can successfully connect to the database, you are going to create two tables with the same name and column across two different schemas. In following steps of the lab you are going to virtualize these tables in IBM Cloud Paks for Data and fold them together into a single table. \n",
    "\n",
    "The next cell sets the default schema to your engineer name followed by 'A'. Notice how you can set a python variable and substitute it into the SQL Statement in the cell. The **-e** option echos the command. \n",
    "\n",
    "Run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><pre style=\"font-family: monospace; border:2px; border-style:solid; border-color:#008000; background-color:#e6ffe6; padding: 1em;\">SET CURRENT SCHEMA LABDATAENGINEER1A</pre></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "schema = engineer+'A'\n",
    "%sql -e SET CURRENT SCHEMA {schema}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run next cell to create a table with a single INTEGER column containing values from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A\n",
       "0   1\n",
       "1   2\n",
       "2   3\n",
       "3   4\n",
       "4   5\n",
       "5   6\n",
       "6   7\n",
       "7   8\n",
       "8   9\n",
       "9  10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE DISCOVER (A INT);\n",
    "INSERT INTO DISCOVER VALUES 1,2,3,4,5,6,7,8,9,10;\n",
    "SELECT * FROM DISCOVER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next two cells to create the same table in a schema ending in **B**. It is populated with values from 11 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABDATAENGINEER1B\n",
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "schema = engineer+'B'\n",
    "print(schema)\n",
    "%sql SET CURRENT SCHEMA {schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A\n",
       "0  11\n",
       "1  12\n",
       "2  13\n",
       "3  14\n",
       "4  15\n",
       "5  16\n",
       "6  17\n",
       "7  18\n",
       "8  19\n",
       "9  20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE DISCOVER (A INT);\n",
    "INSERT INTO DISCOVER VALUES 11,12,13,14,15,16,17,18,19,20;\n",
    "SELECT * FROM DISCOVER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see all the tables in the database called **DISCOVER**. You may see tables created by other people running the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABSCHEMA</th>\n",
       "      <th>TABNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DATAENGINEER1A</td>\n",
       "      <td>DISCOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DATAENGINEER1B</td>\n",
       "      <td>DISCOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LABDATAENGINEER1A</td>\n",
       "      <td>DISCOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LABDATAENGINEER1B</td>\n",
       "      <td>DISCOVER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TABSCHEMA   TABNAME\n",
       "0     DATAENGINEER1A  DISCOVER\n",
       "1     DATAENGINEER1B  DISCOVER\n",
       "2  LABDATAENGINEER1A  DISCOVER\n",
       "3  LABDATAENGINEER1B  DISCOVER"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT TABSCHEMA, TABNAME FROM SYSCAT.TABLES WHERE TABNAME = 'DISCOVER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtualizing your new Tables\n",
    "Now that you have created two new tables you can virtualize that data and make it look like a single table in your database.\n",
    "1. Return to the IBM Cloud Pak for Data Console\n",
    "2. Click **Virtualize** in the Dat Virtualization menu\n",
    "3. Enter **DISCOVER** in the search bar and hit Enter. Now you can see that your new tables have automatically been discovered by IBM Cloud Pak for Data. You will see your tables listed under the LABDATAENGINEER schemas you used when you created your tables. You will also like see other lab participant tables.\n",
    "4. Select the two tables you just created by clicking the **check box** beside each table\n",
    "5. Click **Add to Cart**\n",
    "6. Click **View Cart**\n",
    "7. Change the name of your two tables from DISCOVER to **DISCOVERA** and **DISCOVERB**. These are the new names that you will be able to use to find your tables in the Data Virtualization database. Don't change the Schema name. It is unique to your current userid. \n",
    "\n",
    "9. Click the **back arrow** beside **Review cart and virtualize tables**. We are going to add one more thing to your cart.\n",
    "10. Click the checkbox beside **Automatically group tables**. Notice how all the tables called **DISCOVER** have been grouped together into a single entry.\n",
    "11. Select the row were all the DISCOVER table have been grouped together\n",
    "12. Click **Add to cart**\n",
    "13. Click **View cart**\n",
    "14. However over the elipsis icon at the right side of the list for the **DISCOVER** table\n",
    "15. Select **Edit grouped tables**\n",
    "16. Deselect all the tables except for those in one of the schemas you created. You should now have two tables selected. \n",
    "17. Click Apply\n",
    "17. Change the name of the new combined table **DISCOVERFOLD**\n",
    "18. Select a project from the drop down list that corresponds to your current user id. \n",
    "19. From the elpsis menu select **Preview** for each of the three tables in your list. The new virtualizaed table **DISCOVERA** should contain values from 1-10. The new virtualized table **DISCOVERB** should contain values from 11-20. The **DISCOVERFOLD** virtualized table should contain values from 1-20.\n",
    "20. Click **Virtualize**. You should that three new virtual tables have been created. \n",
    "21. Click **View my virtualized data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with your new tables\n",
    "1. Enter **DISCOVER** in the Find field. \n",
    "You should see the three virtual tables you just created. Notice that you do not see tables that other users have created. By default, Data Engineers only see virtualized tables they have virtualized or virtual tables where they have been given access by other users. \n",
    "2. Click **Preview** beside the **DISCOVERFOLD** table to confirm that it contains 20 rows. \n",
    "3. Click **SQL Editor** from the Data Virtualization menu\n",
    "4. Click **Blank** to create a new blank SQL Script\n",
    "4. Enter **SELECT * FROM DISCOVERFOLD;** into the SQL Editor\n",
    "5. Click **Run All**. You should see 20 rows returned in the result. \n",
    "\n",
    "Notice that you didn't have to specify the schema for your new virtual tables. The SQL Editor automatically uses the schema associated with your userid that was used when you created your new tables. \n",
    "\n",
    "Now you can:\n",
    "* Create connection to a remote data source \n",
    "* Make a new or existing table in that remote data source look and act like a local table \n",
    "* Fold data from different tables in the same data source or access data sources by folding it together into a single virtual table\n",
    "\n",
    "In the next steps you will use more complex data structure and learn how to combine data from multiple tables together into easy to consume views and then share with other users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Data Virtualization \n",
    "#### Combining Data Together\n",
    "The IBM Cloud Pak for Data Virtualization Administrator has set up more complex data from multiple source for the next steps. The administrator has also given you access to this virtualized data. You may have noticed this in previous steps. \n",
    "1. Select **My virtualized data** from the Data Virtualiztion menu. All of these virtualized tables look and act like normal Db2 tables. \n",
    "2. Click **Preview** for any of the tables to see what they contain. \n",
    "\n",
    "The virtualized tables in the **FOLDING** schema have all been created by combinig the same tables from different data source. Folding isn't something that is restricted to the same data source in the simple example you just completed.\n",
    "\n",
    "The virtaulized tables in the **TRADING** schema are view of complex queries that were use to combine data from multiple data source to answer specific business questions. \n",
    "\n",
    "3. Select **SQL Editor** from the Data Virtualization menu.\n",
    "4. Select **Script Library**\n",
    "5. Search for **OHIO**\n",
    "6. Select and expand the **OHIO Customer** query\n",
    "7. Click the **Open a script to edit** icon to open the script in the SQL Editor\n",
    "8. Click **Run All**\n",
    "\n",
    "This script is a complex SQL join query that uses data from all the virtualize data sources you explored in the first steps of this lab. While the SQL looks complex the author of the query did not have be aware that the data was coming from multiple sources. Everything used in this query looks like it comes from a single database, not eight different data sources across eight different systems on premesis or in the Cloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Complex SQL Simple to Consume\n",
    "You can easily make this complex query easy for a user to consume. Instead of shaing this query with other users, you can wrap the query into a view that looks and acts like a simple table. \n",
    "1. Enter **CREATE VIEW MYOHIOQUERY AS** in the SQL Editor at the first line below the comment and before the **WITH** clause\n",
    "2. Click **Run all**\n",
    "3. Click **+** to **Add a new script**\n",
    "4. Click **Blank**\n",
    "4. Enter **SELECT * FROM MYOHIOQUERY;**\n",
    "5. Click **Run all**\n",
    "\n",
    "Now you have a very simple virtualized table that is pulling data from eight different data sources, combining the data together to resolve a complex business problem. In the next step you will share your new virtualized data with a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharing Virtualized Tables\n",
    "1. Select **My virtualized data** from the Data Virtualization Menu.\n",
    "2. Click **Manage Access** from the elipsis menu to the right of the **MYOHIOQUERY** virtualized table\n",
    "3. Click **Grant access**\n",
    "4. Select the **LABUSERx** id associated with your lab. If you are LABDATAENGINEER5, then select LABUSER5.\n",
    "5. Click **Add**\n",
    "\n",
    "You should now see that your **LABUSER** id has view only access to the new virtualized table. Nextyou switch to your LABUSERx id to check that you can see the data you have just granted access for.\n",
    "\n",
    "6. Click the user icon at the very top right of the console\n",
    "7. Click **Log out**\n",
    "8. Sign in using the LABUSER id specified by your lab instructor\n",
    "9. Click the three bar menu at the top left of the IBM Cloud Pak for Data console\n",
    "10. Select **Data Virtualization**\n",
    "\n",
    "You should see the **MYOHIOQUERY** with the schema from your engineer userid in the list of virtualized data.\n",
    "\n",
    "11. Make a note of the schema of the MYOHIOQUERY in your list of virtualized tables. It starts with **USER**.\n",
    "12. Select the **SQL Editor** from the Data virtualization menu\n",
    "13. Click **Blank** to open a new SQL Editor window\n",
    "14. Enter **SELECT * FROM USERxxxx.MYOHIOQUERY** where xxxx is the user number of your engineer user. The view created by your engineer user was created in their default schema. \n",
    "15. Click **Run all**\n",
    "16. Add the following to your query: **WHERE TOTAL > 3000 ORDER BY TOTAL**\n",
    "17. Click **</>** to format the query so it is easiler to read\n",
    "18. Click **Run all**\n",
    "\n",
    "You can see how you have just make a very complex data set extremely easy to consume by a data user. They don't have to know how to connect to multiple data sources or how to combine the data using complex SQL. You can hide that complexity while ensuring only the right user has access to the right data. \n",
    "\n",
    "In the next steps you will learn how to access virtualized data from outside of IBM Cloud Pak for Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Virtualized Data from outside of IBM Cloud Pak for Data\n",
    "In the next set of steps you will connect to virtualized data from outside of IBM Cloud Pak for Data. The connection appears just like connecting to a single database. All the complexity of a dozens of tables across multiple databases on different on premesis and cloud providers is now as simple as connecting to a single database and querying a table. \n",
    "\n",
    "We are going to connect to the IBM Cloud Pak for Data Virtaulization database in exactly the same way we connected to a Db2 database earlier in this lab. However we need to change the detailed connection information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CONNECT TO BLUDB USER user999 USING t1cz?K9-X1_Y-2Wi HOST services-uscentral.skytap.com PORT 9094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show how to create a join view:\n",
    "* Select table STOCK_TRANSACTIONS\n",
    "* Select table STOCK_SYMBOLS\n",
    "* Click Join View\n",
    "* In table STOCK_SYMBOLS: deselect SYMBOL\n",
    "* In table STOCK_HISTORY: deselct _ID\n",
    "* Click STOCK_TRANSACTION.SYMBOLS and drag to STOCK_SYMBOLS.SYMBOL\n",
    "* Click Open in SQL Editor\n",
    "* Click Back button on top of the screen\n",
    "* Click JOIN\n",
    "* Type view name VIEW__STOCK_TRANSACTIONS__STOCK_SYMBOLS\n",
    "* Type schema name DVDEMO\n",
    "* Click NEXT\n",
    "* Select project DVDEMO\n",
    "* Click CREATE VIEW -> Popup window \"Join view created\" apears\n",
    "* Click View my virtualized data\n",
    "* Click the 3 dots besides object VIEW__STOCK_TRANSACTIONS__STOCK_SYMBOLS\n",
    "* Click Preview\n",
    "* Click Manage Access\n",
    "* Click Grant Access\n",
    "* Select user ctp\n",
    "* Click Add\n",
    "* Click Back button on top of the screen -> take you back to My virtualized data screen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show SQL editor and preconfigured scripts:\n",
    "**Prep steps:**\n",
    "* Go to SQL Editor and open the following scripts: Ohio customers, 30 day moving average\n",
    "* Click Ohio Customers to make sure this is preselected\n",
    "\n",
    "**Steps:**\n",
    "* Click Menu\n",
    "* Click SQL Editor\n",
    "* Click 30 day moving average\n",
    "* Click Script Library\n",
    "* Click arrow besides 3% stocks\n",
    "* Click icon Open a script to edit\n",
    "* Click Run all -> the query result is displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show how to deploy the CPD DV service from an external Jupyter notebook\n",
    "* Open the Connections Info page of the DV service and show the connection information\n",
    "* Switch to different brower window that shows external Jupyter Notebooks console\n",
    "* Run through the notebook from top to bottom and show the connect to the DV layer and the execution of the sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = user+'A'\n",
    "%sql DROP TABLE {schema}.DISCOVER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = user+'B'\n",
    "%sql DROP TABLE {schema}.DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019, Peter Kohlmann [kohlmann@ca.ibm.com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
